{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d55a639",
   "metadata": {},
   "source": [
    "o\tImplement the main steps of a Shallow Neural Network\n",
    "•\tUnderstand the dataset\n",
    "•\tImplement your first Forward and Backward propagation\n",
    "•\tImplement activation function, gradient descent\n",
    "•\tBuild Neural Network Model\n",
    "•\tTest and optimize the model\n",
    "•\tMake Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00cea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704be420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0370a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'tanh')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10, 4])\n",
    "x = np.linspace(-10, 10)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, sigmoid(x))\n",
    "plt.title('sigmoid')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x, tanh(x))\n",
    "plt.title('tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c23f8a",
   "metadata": {},
   "source": [
    "# Generate Sample Dataset\n",
    "generate a simple binary classification task with 5000 data points and 20 features for later model validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c0fb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (4000, 20)\n",
      "test shape (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=5000, random_state=123)\n",
    "\n",
    "X_train, X_test = X[:4000], X[4000:]\n",
    "y_train, y_test = y[:4000], y[4000:]\n",
    "\n",
    "print('train shape', X_train.shape)\n",
    "print('test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398c66a",
   "metadata": {},
   "source": [
    "# Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6741e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape (10, 20)\n",
      "b1 shape (10, 1)\n",
      "W2 shape (1, 10)\n",
      "b2 shape (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Weights Initialization\n",
    "def init_weights(n_input, n_hidden, n_output):\n",
    "    params = {}\n",
    "    params['W1'] = np.random.randn(n_hidden, n_input) * 0.01\n",
    "    params['b1'] = np.zeros((n_hidden, 1))\n",
    "    params['W2'] = np.random.randn(n_output, n_hidden) * 0.01\n",
    "    params['b2'] = np.zeros((n_output, 1))\n",
    "    \n",
    "    return params\n",
    "  \n",
    "  \n",
    "params = init_weights(20, 10, 1)\n",
    "\n",
    "print('W1 shape', params['W1'].shape)\n",
    "print('b1 shape', params['b1'].shape)\n",
    "print('W2 shape', params['W2'].shape)\n",
    "print('b2 shape', params['b2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a423a4e3",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd2404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, params):\n",
    "    \"\"\"\n",
    "    X: need to have shape (n_features x m_samples)\n",
    "    \"\"\"\n",
    "    W1, b1, W2, b2 = params['W1'], params['b1'], params['W2'], params['b2']\n",
    "    A0 = X\n",
    "    \n",
    "    cache = {}\n",
    "    Z1 = np.dot(W1, A0) + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache['Z1'] = Z1\n",
    "    cache['A1'] = A1\n",
    "    cache['Z2'] = Z2\n",
    "    cache['A2'] = A2\n",
    "    return  cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0b1f7",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baff76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y, Y_hat):\n",
    "    \"\"\"\n",
    "    Y: vector of true value\n",
    "    Y_hat: vector of predicted value\n",
    "    \"\"\"\n",
    "    assert Y.shape[0] == 1\n",
    "    assert Y.shape == Y_hat.shape\n",
    "    m = Y.shape[1]\n",
    "    s = Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat)\n",
    "    loss = -np.sum(s) / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0737a196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.8348196603835148\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([np.random.choice([0, 1])\n",
    "for i in range(10)]).reshape(1, -1)\n",
    "Y_hat = np.random.uniform(0, 1, 10).reshape(1, -1)\n",
    "\n",
    "l = loss(Y, Y_hat)\n",
    "print(f'loss {l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b93b2",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52567e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(params, cache, X, Y):\n",
    "    \"\"\"\n",
    "    [From coursera deep-learning course]\n",
    "    params: we initiate above with W1, b1, W2, b2\n",
    "    cache: the intermediate caculation we saved with Z1, A1, Z2, A2\n",
    "    X: shape of (n_x, m)\n",
    "    Y: shape (n_y, m)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "\n",
    "    W1 = params['W1']\n",
    "    W2 = params['W2']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25c1b2",
   "metadata": {},
   "source": [
    "# Batch Loader\n",
    " * Ensemble everything into a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56be158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNN:\n",
    "    def __init__(self, n_input, n_hidden, n_output):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.params = {}\n",
    "        self.cache = {}\n",
    "        self.grads = {}\n",
    "        \n",
    "    def compute_loss(self, Y, Y_hat):\n",
    "        \"\"\"\n",
    "        Y: vector of true value\n",
    "        Y_hat: vector of predicted value\n",
    "        \"\"\"\n",
    "        assert Y.shape[0] == 1\n",
    "        assert Y.shape == Y_hat.shape\n",
    "        m = Y.shape[1]\n",
    "        s = Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat)\n",
    "        loss = -np.sum(s) / m\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.params['W1'] = np.random.randn(self.n_hidden, self.n_input) * 0.01\n",
    "        self.params['b1'] = np.zeros((self.n_hidden, 1))\n",
    "        self.params['W2'] = np.random.randn(self.n_output, self.n_hidden) * 0.01\n",
    "        self.params['b2'] = np.zeros((self.n_output, 1))\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X: need to have shape (n_features x m_samples)\n",
    "        \"\"\"\n",
    "        W1, b1, W2, b2 = self.params['W1'], self.params['b1'], self.params['W2'], self.params['b2']\n",
    "        A0 = X\n",
    "\n",
    "        Z1 = np.dot(W1, A0) + b1\n",
    "        A1 = tanh(Z1)\n",
    "        Z2 = np.dot(W2, A1) + b2\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        self.cache['Z1'] = Z1\n",
    "        self.cache['A1'] = A1\n",
    "        self.cache['Z2'] = Z2\n",
    "        self.cache['A2'] = A2\n",
    "     \n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        \"\"\"\n",
    "        [From coursera deep-learning course]\n",
    "        params: we initiate above with W1, b1, W2, b2\n",
    "        cache: the intermediate caculation we saved with Z1, A1, Z2, A2\n",
    "        X: shape of (n_x, m)\n",
    "        Y: shape (n_y, m)\n",
    "        \"\"\"\n",
    "\n",
    "        m = X.shape[1]\n",
    "\n",
    "        W1 = self.params['W1']\n",
    "        W2 = self.params['W2']\n",
    "        A1 = self.cache['A1']\n",
    "        A2 = self.cache['A2']\n",
    "\n",
    "        dZ2 = A2 - Y\n",
    "        dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "        db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "        dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "        db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        self.grads = {\"dW1\": dW1,\n",
    "                      \"db1\": db1,\n",
    "                      \"dW2\": dW2,\n",
    "                      \"db2\": db2}\n",
    "\n",
    "        \n",
    "    def get_batch_indices(self, X_train, batch_size):\n",
    "        n = X_train.shape[0]\n",
    "        indices = [range(i, i+batch_size) for i in range(0, n, batch_size)]\n",
    "        return indices\n",
    "    \n",
    "    \n",
    "    def update_weights(self, lr):\n",
    "        W1, b1, W2, b2 = self.params['W1'], self.params['b1'], self.params['W2'], self.params['b2']\n",
    "        dW1, db1, dW2, db2 = self.grads['dW1'], self.grads['db1'], self.grads['dW2'], self.grads['db2']\n",
    "        self.params['W1'] -= dW1\n",
    "        self.params['W2'] -= dW2\n",
    "        self.params['b1'] -= db1\n",
    "        self.params['b2'] -= db2\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train, batch_size=32, n_iterations=100, lr=0.01):\n",
    "        self.init_weights()\n",
    "        \n",
    "        indices = self.get_batch_indices(X_train, batch_size)\n",
    "        for i in range(n_iterations):\n",
    "            for ind in indices:\n",
    "                X = X_train[ind, :].T\n",
    "                Y = y_train[ind].reshape(1, batch_size)\n",
    "                \n",
    "                self.forward(X)\n",
    "                self.backward(X, Y)\n",
    "                self.update_weights(lr)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                Y_hat = self.cache['A2']\n",
    "                loss = self.compute_loss(Y, Y_hat)\n",
    "                print(f'iteration {i}: loss {loss}')\n",
    "            \n",
    "            \n",
    "    def predict(self, X):\n",
    "        W1, b1, W2, b2 = self.params['W1'], self.params['b1'], self.params['W2'], self.params['b2']\n",
    "        A0 = X\n",
    "\n",
    "        Z1 = np.dot(W1, A0) + b1\n",
    "        A1 = tanh(Z1)\n",
    "        Z2 = np.dot(W2, A1) + b2\n",
    "        A2 = sigmoid(Z2)\n",
    "\n",
    "        return A2\n",
    "\n",
    "    \n",
    "def accuracy(Y, Y_pred):\n",
    "    \"\"\"\n",
    "    Y: vector of true value\n",
    "    Y_pred: vector of predicted value\n",
    "    \"\"\"\n",
    "    def _to_binary(x):\n",
    "        return 1 if x > .5 else 0\n",
    "\n",
    "    assert Y.shape[0] == 1\n",
    "    assert Y.shape == Y_pred.shape\n",
    "    Y_pred = np.vectorize(_to_binary)(Y_pred)\n",
    "    acc = float(np.dot(Y, Y_pred.T) + np.dot(1 - Y, 1 - Y_pred.T))/Y.size\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9477bde5",
   "metadata": {},
   "source": [
    "# Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c88cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShallowNN(20,10,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5506f",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3675bd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss 0.1978708150213788\n",
      "iteration 10: loss 0.09026504287585717\n",
      "iteration 20: loss 0.08232531089864624\n",
      "iteration 30: loss 0.07858080612317006\n",
      "iteration 40: loss 0.07088022626405677\n",
      "iteration 50: loss 0.06190475098705685\n",
      "iteration 60: loss 0.051490523654463834\n",
      "iteration 70: loss 0.04185756915442096\n",
      "iteration 80: loss 0.032456481894594165\n",
      "iteration 90: loss 0.028166038429023422\n",
      "iteration 100: loss 0.026742677524181243\n",
      "iteration 110: loss 0.026012736601906436\n",
      "iteration 120: loss 0.025721107468478114\n",
      "iteration 130: loss 0.025747606350268334\n",
      "iteration 140: loss 0.025674147186837123\n",
      "iteration 150: loss 0.025620801377907294\n",
      "iteration 160: loss 0.025565290155039565\n",
      "iteration 170: loss 0.02545221649413372\n",
      "iteration 180: loss 0.025025942333109327\n",
      "iteration 190: loss 0.02440504894879744\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=100, n_iterations=200, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ef77e",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f11b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.39999999999999%\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test.T)\n",
    "\n",
    "acc = accuracy(y_test.reshape(1,-1), y_preds)\n",
    "print(f'accuracy: {acc*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989eb1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867eb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab32a7e",
   "metadata": {},
   "source": [
    "# Using Keras Library implement shallow neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9020529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b4e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing Data\n",
    "input_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], \"float32\")\n",
    "\n",
    "output_data = np.array([[0], [1], [1], [0]], \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7bcc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='sigmoid'))# 1 hidden layer\n",
    "model.add(Dense(1, activation='sigmoid'))# output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85da8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5fb6fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 - 1s - loss: 0.2534 - binary_accuracy: 0.5000 - 1s/epoch - 1s/step\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 0.2531 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 0.2528 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 0.2525 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 0.2523 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 0.2520 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 0.2518 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 0.2515 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 0.2513 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 0.2512 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 0.2510 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 0.2508 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 0.2507 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 0.2506 - binary_accuracy: 0.2500 - 0s/epoch - 0s/step\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 0.2505 - binary_accuracy: 0.2500 - 0s/epoch - 0s/step\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 0.2504 - binary_accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 0.2503 - binary_accuracy: 0.2500 - 0s/epoch - 0s/step\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 0.2502 - binary_accuracy: 0.2500 - 0s/epoch - 0s/step\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 0.2502 - binary_accuracy: 0.2500 - 16ms/epoch - 16ms/step\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 0.2501 - binary_accuracy: 0.2500 - 0s/epoch - 0s/step\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 0.2501 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 0.2501 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 0.2500 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 0.2499 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 0.2498 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 0.2497 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 3ms/epoch - 3ms/step\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 0.2496 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 8ms/epoch - 8ms/step\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 0.2495 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 0.2494 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 0.2493 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 0.2492 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 0.2491 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 16ms/epoch - 16ms/step\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.5000 - 0s/epoch - 0s/step\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 0.2490 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 0.2489 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 0.2488 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 177/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 178/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 179/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 180/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 181/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 182/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 183/500\n",
      "1/1 - 0s - loss: 0.2487 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 184/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 185/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 186/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 187/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 188/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 189/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 190/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 191/500\n",
      "1/1 - 0s - loss: 0.2486 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 192/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 193/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 194/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 195/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 196/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 197/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 198/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 199/500\n",
      "1/1 - 0s - loss: 0.2485 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 200/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 201/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 202/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 203/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 204/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 205/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 206/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 207/500\n",
      "1/1 - 0s - loss: 0.2484 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 208/500\n",
      "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 209/500\n",
      "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 210/500\n",
      "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 211/500\n",
      "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 212/500\n",
      "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 213/500\n",
      "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 214/500\n",
      "1/1 - 0s - loss: 0.2483 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 215/500\n",
      "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 216/500\n",
      "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 217/500\n",
      "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 218/500\n",
      "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 219/500\n",
      "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 220/500\n",
      "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 221/500\n",
      "1/1 - 0s - loss: 0.2482 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 222/500\n",
      "1/1 - 0s - loss: 0.2481 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 223/500\n",
      "1/1 - 0s - loss: 0.2481 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 224/500\n",
      "1/1 - 0s - loss: 0.2481 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 225/500\n",
      "1/1 - 0s - loss: 0.2481 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 226/500\n",
      "1/1 - 0s - loss: 0.2481 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 227/500\n",
      "1/1 - 0s - loss: 0.2481 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 228/500\n",
      "1/1 - 0s - loss: 0.2481 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 229/500\n",
      "1/1 - 0s - loss: 0.2480 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 230/500\n",
      "1/1 - 0s - loss: 0.2480 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 231/500\n",
      "1/1 - 0s - loss: 0.2480 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 232/500\n",
      "1/1 - 0s - loss: 0.2480 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 233/500\n",
      "1/1 - 0s - loss: 0.2480 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 234/500\n",
      "1/1 - 0s - loss: 0.2480 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 235/500\n",
      "1/1 - 0s - loss: 0.2479 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 236/500\n",
      "1/1 - 0s - loss: 0.2479 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 237/500\n",
      "1/1 - 0s - loss: 0.2479 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 238/500\n",
      "1/1 - 0s - loss: 0.2479 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 239/500\n",
      "1/1 - 0s - loss: 0.2479 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 240/500\n",
      "1/1 - 0s - loss: 0.2479 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 241/500\n",
      "1/1 - 0s - loss: 0.2478 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 242/500\n",
      "1/1 - 0s - loss: 0.2478 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 243/500\n",
      "1/1 - 0s - loss: 0.2478 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 244/500\n",
      "1/1 - 0s - loss: 0.2478 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 245/500\n",
      "1/1 - 0s - loss: 0.2478 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 246/500\n",
      "1/1 - 0s - loss: 0.2478 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 247/500\n",
      "1/1 - 0s - loss: 0.2477 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 248/500\n",
      "1/1 - 0s - loss: 0.2477 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 249/500\n",
      "1/1 - 0s - loss: 0.2477 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 250/500\n",
      "1/1 - 0s - loss: 0.2477 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 251/500\n",
      "1/1 - 0s - loss: 0.2477 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 252/500\n",
      "1/1 - 0s - loss: 0.2477 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 253/500\n",
      "1/1 - 0s - loss: 0.2476 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 254/500\n",
      "1/1 - 0s - loss: 0.2476 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 255/500\n",
      "1/1 - 0s - loss: 0.2476 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 256/500\n",
      "1/1 - 0s - loss: 0.2476 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 257/500\n",
      "1/1 - 0s - loss: 0.2476 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 258/500\n",
      "1/1 - 0s - loss: 0.2475 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 259/500\n",
      "1/1 - 0s - loss: 0.2475 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 260/500\n",
      "1/1 - 0s - loss: 0.2475 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 261/500\n",
      "1/1 - 0s - loss: 0.2475 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 262/500\n",
      "1/1 - 0s - loss: 0.2475 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 263/500\n",
      "1/1 - 0s - loss: 0.2474 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 264/500\n",
      "1/1 - 0s - loss: 0.2474 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 265/500\n",
      "1/1 - 0s - loss: 0.2474 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 266/500\n",
      "1/1 - 0s - loss: 0.2474 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 267/500\n",
      "1/1 - 0s - loss: 0.2474 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 268/500\n",
      "1/1 - 0s - loss: 0.2474 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 269/500\n",
      "1/1 - 0s - loss: 0.2473 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 270/500\n",
      "1/1 - 0s - loss: 0.2473 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 271/500\n",
      "1/1 - 0s - loss: 0.2473 - binary_accuracy: 0.7500 - 4ms/epoch - 4ms/step\n",
      "Epoch 272/500\n",
      "1/1 - 0s - loss: 0.2473 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 273/500\n",
      "1/1 - 0s - loss: 0.2472 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 274/500\n",
      "1/1 - 0s - loss: 0.2472 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 275/500\n",
      "1/1 - 0s - loss: 0.2472 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 276/500\n",
      "1/1 - 0s - loss: 0.2472 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 277/500\n",
      "1/1 - 0s - loss: 0.2472 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 278/500\n",
      "1/1 - 0s - loss: 0.2471 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 279/500\n",
      "1/1 - 0s - loss: 0.2471 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 280/500\n",
      "1/1 - 0s - loss: 0.2471 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 281/500\n",
      "1/1 - 0s - loss: 0.2471 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 282/500\n",
      "1/1 - 0s - loss: 0.2471 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 283/500\n",
      "1/1 - 0s - loss: 0.2470 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 284/500\n",
      "1/1 - 0s - loss: 0.2470 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 285/500\n",
      "1/1 - 0s - loss: 0.2470 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 286/500\n",
      "1/1 - 0s - loss: 0.2470 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 287/500\n",
      "1/1 - 0s - loss: 0.2469 - binary_accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "Epoch 288/500\n",
      "1/1 - 0s - loss: 0.2469 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 289/500\n",
      "1/1 - 0s - loss: 0.2469 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 290/500\n",
      "1/1 - 0s - loss: 0.2469 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 291/500\n",
      "1/1 - 0s - loss: 0.2469 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 292/500\n",
      "1/1 - 0s - loss: 0.2468 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 293/500\n",
      "1/1 - 0s - loss: 0.2468 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 294/500\n",
      "1/1 - 0s - loss: 0.2468 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 295/500\n",
      "1/1 - 0s - loss: 0.2468 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 296/500\n",
      "1/1 - 0s - loss: 0.2467 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 297/500\n",
      "1/1 - 0s - loss: 0.2467 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 298/500\n",
      "1/1 - 0s - loss: 0.2467 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 299/500\n",
      "1/1 - 0s - loss: 0.2467 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 300/500\n",
      "1/1 - 0s - loss: 0.2466 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 301/500\n",
      "1/1 - 0s - loss: 0.2466 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 302/500\n",
      "1/1 - 0s - loss: 0.2466 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 303/500\n",
      "1/1 - 0s - loss: 0.2466 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 304/500\n",
      "1/1 - 0s - loss: 0.2465 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 305/500\n",
      "1/1 - 0s - loss: 0.2465 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 306/500\n",
      "1/1 - 0s - loss: 0.2465 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 307/500\n",
      "1/1 - 0s - loss: 0.2465 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 308/500\n",
      "1/1 - 0s - loss: 0.2464 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 309/500\n",
      "1/1 - 0s - loss: 0.2464 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 310/500\n",
      "1/1 - 0s - loss: 0.2464 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 311/500\n",
      "1/1 - 0s - loss: 0.2464 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 312/500\n",
      "1/1 - 0s - loss: 0.2463 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 313/500\n",
      "1/1 - 0s - loss: 0.2463 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 314/500\n",
      "1/1 - 0s - loss: 0.2463 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 315/500\n",
      "1/1 - 0s - loss: 0.2463 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 316/500\n",
      "1/1 - 0s - loss: 0.2462 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 317/500\n",
      "1/1 - 0s - loss: 0.2462 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 318/500\n",
      "1/1 - 0s - loss: 0.2462 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 319/500\n",
      "1/1 - 0s - loss: 0.2461 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 320/500\n",
      "1/1 - 0s - loss: 0.2461 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 321/500\n",
      "1/1 - 0s - loss: 0.2461 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 322/500\n",
      "1/1 - 0s - loss: 0.2461 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 323/500\n",
      "1/1 - 0s - loss: 0.2460 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 324/500\n",
      "1/1 - 0s - loss: 0.2460 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 325/500\n",
      "1/1 - 0s - loss: 0.2460 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 326/500\n",
      "1/1 - 0s - loss: 0.2459 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 327/500\n",
      "1/1 - 0s - loss: 0.2459 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 328/500\n",
      "1/1 - 0s - loss: 0.2459 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 329/500\n",
      "1/1 - 0s - loss: 0.2459 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 330/500\n",
      "1/1 - 0s - loss: 0.2458 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 331/500\n",
      "1/1 - 0s - loss: 0.2458 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 332/500\n",
      "1/1 - 0s - loss: 0.2458 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 333/500\n",
      "1/1 - 0s - loss: 0.2457 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 334/500\n",
      "1/1 - 0s - loss: 0.2457 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 335/500\n",
      "1/1 - 0s - loss: 0.2457 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 336/500\n",
      "1/1 - 0s - loss: 0.2456 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 337/500\n",
      "1/1 - 0s - loss: 0.2456 - binary_accuracy: 0.7500 - 9ms/epoch - 9ms/step\n",
      "Epoch 338/500\n",
      "1/1 - 0s - loss: 0.2456 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
      "Epoch 339/500\n",
      "1/1 - 0s - loss: 0.2456 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 340/500\n",
      "1/1 - 0s - loss: 0.2455 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 341/500\n",
      "1/1 - 0s - loss: 0.2455 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 342/500\n",
      "1/1 - 0s - loss: 0.2455 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 343/500\n",
      "1/1 - 0s - loss: 0.2454 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 344/500\n",
      "1/1 - 0s - loss: 0.2454 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 345/500\n",
      "1/1 - 0s - loss: 0.2454 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 346/500\n",
      "1/1 - 0s - loss: 0.2453 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 347/500\n",
      "1/1 - 0s - loss: 0.2453 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 348/500\n",
      "1/1 - 0s - loss: 0.2453 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 349/500\n",
      "1/1 - 0s - loss: 0.2452 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 350/500\n",
      "1/1 - 0s - loss: 0.2452 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 351/500\n",
      "1/1 - 0s - loss: 0.2452 - binary_accuracy: 0.7500 - 23ms/epoch - 23ms/step\n",
      "Epoch 352/500\n",
      "1/1 - 0s - loss: 0.2451 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 353/500\n",
      "1/1 - 0s - loss: 0.2451 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 354/500\n",
      "1/1 - 0s - loss: 0.2451 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 355/500\n",
      "1/1 - 0s - loss: 0.2450 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 356/500\n",
      "1/1 - 0s - loss: 0.2450 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 357/500\n",
      "1/1 - 0s - loss: 0.2449 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 358/500\n",
      "1/1 - 0s - loss: 0.2449 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 359/500\n",
      "1/1 - 0s - loss: 0.2449 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 360/500\n",
      "1/1 - 0s - loss: 0.2448 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 361/500\n",
      "1/1 - 0s - loss: 0.2448 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 362/500\n",
      "1/1 - 0s - loss: 0.2448 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 363/500\n",
      "1/1 - 0s - loss: 0.2447 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 364/500\n",
      "1/1 - 0s - loss: 0.2447 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 365/500\n",
      "1/1 - 0s - loss: 0.2447 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 366/500\n",
      "1/1 - 0s - loss: 0.2446 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 367/500\n",
      "1/1 - 0s - loss: 0.2446 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 368/500\n",
      "1/1 - 0s - loss: 0.2445 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 369/500\n",
      "1/1 - 0s - loss: 0.2445 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 370/500\n",
      "1/1 - 0s - loss: 0.2445 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 371/500\n",
      "1/1 - 0s - loss: 0.2444 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 372/500\n",
      "1/1 - 0s - loss: 0.2444 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 373/500\n",
      "1/1 - 0s - loss: 0.2443 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 374/500\n",
      "1/1 - 0s - loss: 0.2443 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 375/500\n",
      "1/1 - 0s - loss: 0.2443 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 376/500\n",
      "1/1 - 0s - loss: 0.2442 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 377/500\n",
      "1/1 - 0s - loss: 0.2442 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 378/500\n",
      "1/1 - 0s - loss: 0.2441 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 379/500\n",
      "1/1 - 0s - loss: 0.2441 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 380/500\n",
      "1/1 - 0s - loss: 0.2441 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 381/500\n",
      "1/1 - 0s - loss: 0.2440 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 382/500\n",
      "1/1 - 0s - loss: 0.2440 - binary_accuracy: 0.7500 - 17ms/epoch - 17ms/step\n",
      "Epoch 383/500\n",
      "1/1 - 0s - loss: 0.2439 - binary_accuracy: 0.7500 - 15ms/epoch - 15ms/step\n",
      "Epoch 384/500\n",
      "1/1 - 0s - loss: 0.2439 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 385/500\n",
      "1/1 - 0s - loss: 0.2439 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 386/500\n",
      "1/1 - 0s - loss: 0.2438 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 387/500\n",
      "1/1 - 0s - loss: 0.2438 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 388/500\n",
      "1/1 - 0s - loss: 0.2437 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 389/500\n",
      "1/1 - 0s - loss: 0.2437 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 390/500\n",
      "1/1 - 0s - loss: 0.2436 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 391/500\n",
      "1/1 - 0s - loss: 0.2436 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 392/500\n",
      "1/1 - 0s - loss: 0.2436 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 393/500\n",
      "1/1 - 0s - loss: 0.2435 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 394/500\n",
      "1/1 - 0s - loss: 0.2435 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 395/500\n",
      "1/1 - 0s - loss: 0.2434 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 396/500\n",
      "1/1 - 0s - loss: 0.2434 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 397/500\n",
      "1/1 - 0s - loss: 0.2433 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 398/500\n",
      "1/1 - 0s - loss: 0.2433 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 399/500\n",
      "1/1 - 0s - loss: 0.2432 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 400/500\n",
      "1/1 - 0s - loss: 0.2432 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 401/500\n",
      "1/1 - 0s - loss: 0.2431 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 402/500\n",
      "1/1 - 0s - loss: 0.2431 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 403/500\n",
      "1/1 - 0s - loss: 0.2430 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 404/500\n",
      "1/1 - 0s - loss: 0.2430 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 405/500\n",
      "1/1 - 0s - loss: 0.2430 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 406/500\n",
      "1/1 - 0s - loss: 0.2429 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 407/500\n",
      "1/1 - 0s - loss: 0.2429 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 408/500\n",
      "1/1 - 0s - loss: 0.2428 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 409/500\n",
      "1/1 - 0s - loss: 0.2428 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 410/500\n",
      "1/1 - 0s - loss: 0.2427 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 411/500\n",
      "1/1 - 0s - loss: 0.2427 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 412/500\n",
      "1/1 - 0s - loss: 0.2426 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 413/500\n",
      "1/1 - 0s - loss: 0.2426 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 414/500\n",
      "1/1 - 0s - loss: 0.2425 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 415/500\n",
      "1/1 - 0s - loss: 0.2425 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 416/500\n",
      "1/1 - 0s - loss: 0.2424 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 417/500\n",
      "1/1 - 0s - loss: 0.2424 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 418/500\n",
      "1/1 - 0s - loss: 0.2423 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 419/500\n",
      "1/1 - 0s - loss: 0.2423 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 420/500\n",
      "1/1 - 0s - loss: 0.2422 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 421/500\n",
      "1/1 - 0s - loss: 0.2421 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 422/500\n",
      "1/1 - 0s - loss: 0.2421 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 423/500\n",
      "1/1 - 0s - loss: 0.2420 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 424/500\n",
      "1/1 - 0s - loss: 0.2420 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 425/500\n",
      "1/1 - 0s - loss: 0.2419 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 426/500\n",
      "1/1 - 0s - loss: 0.2419 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 427/500\n",
      "1/1 - 0s - loss: 0.2418 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 428/500\n",
      "1/1 - 0s - loss: 0.2418 - binary_accuracy: 0.7500 - 13ms/epoch - 13ms/step\n",
      "Epoch 429/500\n",
      "1/1 - 0s - loss: 0.2417 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 430/500\n",
      "1/1 - 0s - loss: 0.2417 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 431/500\n",
      "1/1 - 0s - loss: 0.2416 - binary_accuracy: 0.7500 - 4ms/epoch - 4ms/step\n",
      "Epoch 432/500\n",
      "1/1 - 0s - loss: 0.2415 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 433/500\n",
      "1/1 - 0s - loss: 0.2415 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 434/500\n",
      "1/1 - 0s - loss: 0.2414 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 435/500\n",
      "1/1 - 0s - loss: 0.2414 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 436/500\n",
      "1/1 - 0s - loss: 0.2413 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 437/500\n",
      "1/1 - 0s - loss: 0.2413 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 438/500\n",
      "1/1 - 0s - loss: 0.2412 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 439/500\n",
      "1/1 - 0s - loss: 0.2411 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 440/500\n",
      "1/1 - 0s - loss: 0.2411 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 441/500\n",
      "1/1 - 0s - loss: 0.2410 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 442/500\n",
      "1/1 - 0s - loss: 0.2410 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 443/500\n",
      "1/1 - 0s - loss: 0.2409 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 444/500\n",
      "1/1 - 0s - loss: 0.2408 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 445/500\n",
      "1/1 - 0s - loss: 0.2408 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 446/500\n",
      "1/1 - 0s - loss: 0.2407 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 447/500\n",
      "1/1 - 0s - loss: 0.2407 - binary_accuracy: 0.7500 - 8ms/epoch - 8ms/step\n",
      "Epoch 448/500\n",
      "1/1 - 0s - loss: 0.2406 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 449/500\n",
      "1/1 - 0s - loss: 0.2405 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 450/500\n",
      "1/1 - 0s - loss: 0.2405 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 451/500\n",
      "1/1 - 0s - loss: 0.2404 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 452/500\n",
      "1/1 - 0s - loss: 0.2403 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 453/500\n",
      "1/1 - 0s - loss: 0.2403 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 454/500\n",
      "1/1 - 0s - loss: 0.2402 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 455/500\n",
      "1/1 - 0s - loss: 0.2401 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 456/500\n",
      "1/1 - 0s - loss: 0.2401 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 457/500\n",
      "1/1 - 0s - loss: 0.2400 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 458/500\n",
      "1/1 - 0s - loss: 0.2400 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 459/500\n",
      "1/1 - 0s - loss: 0.2399 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 460/500\n",
      "1/1 - 0s - loss: 0.2398 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 461/500\n",
      "1/1 - 0s - loss: 0.2398 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 462/500\n",
      "1/1 - 0s - loss: 0.2397 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 463/500\n",
      "1/1 - 0s - loss: 0.2396 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 464/500\n",
      "1/1 - 0s - loss: 0.2396 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 465/500\n",
      "1/1 - 0s - loss: 0.2395 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 466/500\n",
      "1/1 - 0s - loss: 0.2394 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 467/500\n",
      "1/1 - 0s - loss: 0.2393 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 468/500\n",
      "1/1 - 0s - loss: 0.2393 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 469/500\n",
      "1/1 - 0s - loss: 0.2392 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 470/500\n",
      "1/1 - 0s - loss: 0.2391 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 471/500\n",
      "1/1 - 0s - loss: 0.2391 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 472/500\n",
      "1/1 - 0s - loss: 0.2390 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 473/500\n",
      "1/1 - 0s - loss: 0.2389 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 474/500\n",
      "1/1 - 0s - loss: 0.2388 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 475/500\n",
      "1/1 - 0s - loss: 0.2388 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 476/500\n",
      "1/1 - 0s - loss: 0.2387 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 477/500\n",
      "1/1 - 0s - loss: 0.2386 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 478/500\n",
      "1/1 - 0s - loss: 0.2386 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 479/500\n",
      "1/1 - 0s - loss: 0.2385 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 480/500\n",
      "1/1 - 0s - loss: 0.2384 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 481/500\n",
      "1/1 - 0s - loss: 0.2383 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 482/500\n",
      "1/1 - 0s - loss: 0.2383 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 483/500\n",
      "1/1 - 0s - loss: 0.2382 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 484/500\n",
      "1/1 - 0s - loss: 0.2381 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 485/500\n",
      "1/1 - 0s - loss: 0.2380 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 486/500\n",
      "1/1 - 0s - loss: 0.2379 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 487/500\n",
      "1/1 - 0s - loss: 0.2379 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 488/500\n",
      "1/1 - 0s - loss: 0.2378 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 489/500\n",
      "1/1 - 0s - loss: 0.2377 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 490/500\n",
      "1/1 - 0s - loss: 0.2376 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 491/500\n",
      "1/1 - 0s - loss: 0.2375 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 492/500\n",
      "1/1 - 0s - loss: 0.2375 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 493/500\n",
      "1/1 - 0s - loss: 0.2374 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 494/500\n",
      "1/1 - 0s - loss: 0.2373 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 495/500\n",
      "1/1 - 0s - loss: 0.2372 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 496/500\n",
      "1/1 - 0s - loss: 0.2371 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 497/500\n",
      "1/1 - 0s - loss: 0.2371 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 498/500\n",
      "1/1 - 0s - loss: 0.2370 - binary_accuracy: 0.7500 - 0s/epoch - 0s/step\n",
      "Epoch 499/500\n",
      "1/1 - 0s - loss: 0.2369 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n",
      "Epoch 500/500\n",
      "1/1 - 0s - loss: 0.2368 - binary_accuracy: 0.7500 - 16ms/epoch - 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f57dbf5ca0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_data, output_data, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0efdeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 333ms/step\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "print(model.predict(input_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ea30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
